# 数据仓库设计文档

## 🏗️ 数据仓库架构概览

### 整体架构设计
```
┌─────────────────────────────────────────────────────────────┐
│                    数据源层 (Data Sources)                   │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐        │
│  │ ERP系统     │  │ CRM系统     │  │ 电商平台    │        │
│  │ (订单数据)  │  │ (客户数据)  │  │ (销售数据)  │        │
│  └─────────────┘  └─────────────┘  └─────────────┘        │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐        │
│  │ 财务系统    │  │ 库存系统    │  │ 物流系统    │        │
│  │ (财务数据)  │  │ (库存数据)  │  │ (配送数据)  │        │
│  └─────────────┘  └─────────────┘  └─────────────┘        │
└─────────────────────────────────────────────────────────────┘
                              │
┌─────────────────────────────────────────────────────────────┐
│                    数据集成层 (ETL Layer)                    │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐        │
│  │ 数据抽取    │  │ 数据清洗    │  │ 数据加载    │        │
│  │ (Extract)   │  │ (Transform) │  │ (Load)      │        │
│  └─────────────┘  └─────────────┘  └─────────────┘        │
│           Apache Airflow + Kafka + Spark                   │
└─────────────────────────────────────────────────────────────┘
                              │
┌─────────────────────────────────────────────────────────────┐
│                    数据存储层 (Storage Layer)                │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐        │
│  │ ODS层       │  │ DWD层       │  │ DWS层       │        │
│  │ (原始数据)  │  │ (明细数据)  │  │ (汇总数据)  │        │
│  └─────────────┘  └─────────────┘  └─────────────┘        │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐        │
│  │ DIM层       │  │ ADS层       │  │ 实时流      │        │
│  │ (维度数据)  │  │ (应用数据)  │  │ (Stream)    │        │
│  └─────────────┘  └─────────────┘  └─────────────┘        │
│              ClickHouse + Hive + Redis                     │
└─────────────────────────────────────────────────────────────┘
                              │
┌─────────────────────────────────────────────────────────────┐
│                    数据服务层 (Service Layer)                │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐        │
│  │ OLAP引擎    │  │ 查询服务    │  │ API网关     │        │
│  │ (ClickHouse)│  │ (Presto)    │  │ (Gateway)   │        │
│  └─────────────┘  └─────────────┘  └─────────────┘        │
└─────────────────────────────────────────────────────────────┘
                              │
┌─────────────────────────────────────────────────────────────┐
│                    应用层 (Application Layer)                │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐        │
│  │ 移动端APP   │  │ Web管理端   │  │ BI报表      │        │
│  │ (Vue3)      │  │ (React)     │  │ (Tableau)   │        │
│  └─────────────┘  └─────────────┘  └─────────────┘        │
└─────────────────────────────────────────────────────────────┘
```

## 📊 数据仓库分层设计

### 1. ODS层 (Operational Data Store) - 原始数据层

#### 设计原则
- 保持数据原貌，不做任何处理
- 按业务系统分区存储
- 支持全量和增量同步
- 数据保留周期：3年

#### 表结构设计
```sql
-- ERP订单原始数据表
CREATE TABLE ods_erp_orders (
    order_id STRING,
    customer_id STRING,
    employee_id STRING,
    order_date STRING,
    order_amount DECIMAL(15,2),
    order_status STRING,
    product_info STRING,
    create_time TIMESTAMP,
    update_time TIMESTAMP,
    etl_date STRING,
    source_system STRING
) PARTITIONED BY (dt STRING)
STORED AS PARQUET;

-- CRM客户原始数据表
CREATE TABLE ods_crm_customers (
    customer_id STRING,
    customer_name STRING,
    customer_type STRING,
    contact_person STRING,
    phone STRING,
    address STRING,
    create_time TIMESTAMP,
    update_time TIMESTAMP,
    etl_date STRING,
    source_system STRING
) PARTITIONED BY (dt STRING)
STORED AS PARQUET;

-- 库存原始数据表
CREATE TABLE ods_inventory_products (
    product_id STRING,
    product_name STRING,
    category_id STRING,
    unit_price DECIMAL(10,2),
    stock_quantity INT,
    warehouse_id STRING,
    create_time TIMESTAMP,
    update_time TIMESTAMP,
    etl_date STRING,
    source_system STRING
) PARTITIONED BY (dt STRING)
STORED AS PARQUET;
```

### 2. DWD层 (Data Warehouse Detail) - 明细数据层

#### 设计原则
- 数据清洗和标准化
- 建立统一的数据模型
- 保持业务过程的原子性
- 支持历史数据追溯

#### 核心事实表设计
```sql
-- 订单明细事实表
CREATE TABLE dwd_order_detail_fact (
    order_detail_id STRING,
    order_id STRING,
    customer_id STRING,
    employee_id STRING,
    product_id STRING,
    order_date DATE,
    order_time TIMESTAMP,
    quantity INT,
    unit_price DECIMAL(10,2),
    discount_amount DECIMAL(10,2),
    total_amount DECIMAL(15,2),
    order_status STRING,
    payment_method STRING,
    delivery_address STRING,
    create_time TIMESTAMP,
    update_time TIMESTAMP,
    is_deleted TINYINT DEFAULT 0
) PARTITIONED BY (dt STRING)
STORED AS PARQUET;

-- 销售明细事实表
CREATE TABLE dwd_sales_detail_fact (
    sales_id STRING,
    order_id STRING,
    customer_id STRING,
    employee_id STRING,
    product_id STRING,
    sales_date DATE,
    sales_time TIMESTAMP,
    sales_quantity INT,
    sales_amount DECIMAL(15,2),
    cost_amount DECIMAL(15,2),
    profit_amount DECIMAL(15,2),
    profit_rate DECIMAL(5,4),
    channel_id STRING,
    region_id STRING,
    create_time TIMESTAMP,
    update_time TIMESTAMP,
    is_deleted TINYINT DEFAULT 0
) PARTITIONED BY (dt STRING)
STORED AS PARQUET;

-- 库存变动明细事实表
CREATE TABLE dwd_inventory_change_fact (
    change_id STRING,
    product_id STRING,
    warehouse_id STRING,
    change_type STRING, -- IN/OUT/ADJUST
    change_quantity INT,
    change_amount DECIMAL(15,2),
    before_quantity INT,
    after_quantity INT,
    change_date DATE,
    change_time TIMESTAMP,
    operator_id STRING,
    reason STRING,
    create_time TIMESTAMP,
    is_deleted TINYINT DEFAULT 0
) PARTITIONED BY (dt STRING)
STORED AS PARQUET;
```

### 3. DIM层 (Dimension) - 维度数据层

#### 维度表设计
```sql
-- 员工维度表
CREATE TABLE dim_employee (
    employee_id STRING,
    employee_code STRING,
    employee_name STRING,
    department_id STRING,
    department_name STRING,
    position STRING,
    level STRING,
    manager_id STRING,
    hire_date DATE,
    status STRING,
    phone STRING,
    email STRING,
    region_id STRING,
    create_time TIMESTAMP,
    update_time TIMESTAMP,
    effective_date DATE,
    expiry_date DATE,
    is_current TINYINT DEFAULT 1
) STORED AS PARQUET;

-- 客户维度表
CREATE TABLE dim_customer (
    customer_id STRING,
    customer_code STRING,
    customer_name STRING,
    customer_type STRING, -- 个人/企业/代理商
    industry STRING,
    scale STRING, -- 大型/中型/小型
    contact_person STRING,
    phone STRING,
    email STRING,
    address STRING,
    region_id STRING,
    credit_level STRING,
    create_time TIMESTAMP,
    update_time TIMESTAMP,
    effective_date DATE,
    expiry_date DATE,
    is_current TINYINT DEFAULT 1
) STORED AS PARQUET;

-- 商品维度表
CREATE TABLE dim_product (
    product_id STRING,
    product_code STRING,
    product_name STRING,
    category_id STRING,
    category_name STRING,
    brand STRING,
    specification STRING,
    unit STRING,
    unit_price DECIMAL(10,2),
    cost_price DECIMAL(10,2),
    status STRING,
    create_time TIMESTAMP,
    update_time TIMESTAMP,
    effective_date DATE,
    expiry_date DATE,
    is_current TINYINT DEFAULT 1
) STORED AS PARQUET;

-- 时间维度表
CREATE TABLE dim_date (
    date_key STRING,
    full_date DATE,
    year INT,
    quarter INT,
    month INT,
    week INT,
    day INT,
    weekday INT,
    is_weekend TINYINT,
    is_holiday TINYINT,
    holiday_name STRING,
    fiscal_year INT,
    fiscal_quarter INT,
    fiscal_month INT
) STORED AS PARQUET;

-- 地区维度表
CREATE TABLE dim_region (
    region_id STRING,
    region_code STRING,
    region_name STRING,
    parent_region_id STRING,
    region_level INT, -- 1:省 2:市 3:区县
    region_path STRING,
    manager_id STRING,
    create_time TIMESTAMP,
    update_time TIMESTAMP,
    is_current TINYINT DEFAULT 1
) STORED AS PARQUET;
```

### 4. DWS层 (Data Warehouse Summary) - 汇总数据层

#### 轻度汇总表设计
```sql
-- 员工日销售汇总表
CREATE TABLE dws_employee_sales_1d (
    employee_id STRING,
    stat_date DATE,
    order_count INT,
    sales_amount DECIMAL(15,2),
    profit_amount DECIMAL(15,2),
    profit_rate DECIMAL(5,4),
    customer_count INT,
    product_count INT,
    avg_order_amount DECIMAL(15,2),
    max_order_amount DECIMAL(15,2),
    return_count INT,
    return_amount DECIMAL(15,2),
    return_rate DECIMAL(5,4),
    create_time TIMESTAMP,
    update_time TIMESTAMP
) PARTITIONED BY (dt STRING)
STORED AS PARQUET;

-- 客户日消费汇总表
CREATE TABLE dws_customer_consume_1d (
    customer_id STRING,
    stat_date DATE,
    order_count INT,
    consume_amount DECIMAL(15,2),
    product_count INT,
    avg_order_amount DECIMAL(15,2),
    max_order_amount DECIMAL(15,2),
    last_order_date DATE,
    create_time TIMESTAMP,
    update_time TIMESTAMP
) PARTITIONED BY (dt STRING)
STORED AS PARQUET;

-- 商品日销售汇总表
CREATE TABLE dws_product_sales_1d (
    product_id STRING,
    stat_date DATE,
    sales_quantity INT,
    sales_amount DECIMAL(15,2),
    profit_amount DECIMAL(15,2),
    profit_rate DECIMAL(5,4),
    order_count INT,
    customer_count INT,
    avg_price DECIMAL(10,2),
    inventory_quantity INT,
    create_time TIMESTAMP,
    update_time TIMESTAMP
) PARTITIONED BY (dt STRING)
STORED AS PARQUET;
```

### 5. ADS层 (Application Data Service) - 应用数据层

#### 应用主题表设计
```sql
-- 员工业绩分析表
CREATE TABLE ads_employee_performance (
    employee_id STRING,
    employee_name STRING,
    department_name STRING,
    stat_period STRING, -- daily/weekly/monthly/quarterly/yearly
    stat_date DATE,
    
    -- 销售指标
    sales_amount DECIMAL(15,2),
    sales_target DECIMAL(15,2),
    sales_completion_rate DECIMAL(5,4),
    sales_rank INT,
    
    -- 订单指标
    order_count INT,
    order_customers INT,
    order_products INT,
    avg_order_amount DECIMAL(15,2),
    
    -- 客户指标
    visit_customers INT,
    new_customers INT,
    active_customers INT,
    customer_retention_rate DECIMAL(5,4),
    
    -- 商品指标
    distribution_stores INT,
    distribution_products INT,
    inventory_turnover DECIMAL(5,2),
    
    create_time TIMESTAMP,
    update_time TIMESTAMP
) PARTITIONED BY (dt STRING, period STRING)
STORED AS PARQUET;

-- 客户价值分析表
CREATE TABLE ads_customer_value (
    customer_id STRING,
    customer_name STRING,
    customer_type STRING,
    stat_period STRING,
    stat_date DATE,
    
    -- 消费指标
    total_amount DECIMAL(15,2),
    order_count INT,
    avg_order_amount DECIMAL(15,2),
    max_order_amount DECIMAL(15,2),
    
    -- 行为指标
    purchase_frequency DECIMAL(5,2),
    last_purchase_date DATE,
    purchase_cycle INT,
    
    -- 价值分类
    rfm_score STRING,
    customer_level STRING, -- 高价值/中价值/低价值
    lifecycle_stage STRING, -- 新客户/活跃客户/沉睡客户/流失客户
    
    create_time TIMESTAMP,
    update_time TIMESTAMP
) PARTITIONED BY (dt STRING, period STRING)
STORED AS PARQUET;

-- 商品销售分析表
CREATE TABLE ads_product_analysis (
    product_id STRING,
    product_name STRING,
    category_name STRING,
    stat_period STRING,
    stat_date DATE,
    
    -- 销售指标
    sales_quantity INT,
    sales_amount DECIMAL(15,2),
    profit_amount DECIMAL(15,2),
    profit_rate DECIMAL(5,4),
    
    -- 市场指标
    market_share DECIMAL(5,4),
    sales_rank INT,
    growth_rate DECIMAL(5,4),
    
    -- 库存指标
    inventory_quantity INT,
    inventory_amount DECIMAL(15,2),
    turnover_rate DECIMAL(5,2),
    stockout_days INT,
    
    -- 分类标签
    abc_category STRING, -- A类/B类/C类商品
    lifecycle_stage STRING, -- 导入期/成长期/成熟期/衰退期
    
    create_time TIMESTAMP,
    update_time TIMESTAMP
) PARTITIONED BY (dt STRING, period STRING)
STORED AS PARQUET;
```

## 🔄 ETL数据处理流程

### 1. 数据抽取 (Extract)

#### 全量抽取策略
```python
# 全量数据抽取示例
def extract_full_data(source_config, table_name, target_date):
    """
    全量数据抽取
    """
    sql = f"""
    SELECT *
    FROM {table_name}
    WHERE DATE(update_time) <= '{target_date}'
    """
    
    # 执行抽取
    data = execute_sql(source_config, sql)
    
    # 添加ETL元数据
    data['etl_date'] = target_date
    data['source_system'] = source_config['system_name']
    
    return data
```

#### 增量抽取策略
```python
# 增量数据抽取示例
def extract_incremental_data(source_config, table_name, last_update_time):
    """
    增量数据抽取
    """
    sql = f"""
    SELECT *
    FROM {table_name}
    WHERE update_time > '{last_update_time}'
    """
    
    # 执行抽取
    data = execute_sql(source_config, sql)
    
    # 添加ETL元数据
    data['etl_date'] = datetime.now().strftime('%Y-%m-%d')
    data['source_system'] = source_config['system_name']
    
    return data
```

### 2. 数据清洗 (Transform)

#### 数据质量规则
```python
# 数据清洗规则示例
def clean_order_data(raw_data):
    """
    订单数据清洗
    """
    cleaned_data = raw_data.copy()
    
    # 1. 空值处理
    cleaned_data['customer_name'] = cleaned_data['customer_name'].fillna('未知客户')
    cleaned_data['order_amount'] = cleaned_data['order_amount'].fillna(0)
    
    # 2. 数据类型转换
    cleaned_data['order_date'] = pd.to_datetime(cleaned_data['order_date'])
    cleaned_data['order_amount'] = cleaned_data['order_amount'].astype(float)
    
    # 3. 数据校验
    # 订单金额不能为负数
    cleaned_data = cleaned_data[cleaned_data['order_amount'] >= 0]
    
    # 订单日期不能超过当前日期
    cleaned_data = cleaned_data[cleaned_data['order_date'] <= datetime.now()]
    
    # 4. 数据标准化
    # 客户类型标准化
    type_mapping = {
        '个人': 'INDIVIDUAL',
        '企业': 'ENTERPRISE',
        '代理商': 'AGENT'
    }
    cleaned_data['customer_type'] = cleaned_data['customer_type'].map(type_mapping)
    
    # 5. 数据丰富
    # 添加订单年月
    cleaned_data['order_year'] = cleaned_data['order_date'].dt.year
    cleaned_data['order_month'] = cleaned_data['order_date'].dt.month
    
    return cleaned_data
```

### 3. 数据加载 (Load)

#### 批量加载策略
```python
# 批量数据加载示例
def load_data_to_warehouse(data, target_table, partition_date):
    """
    数据加载到数据仓库
    """
    # 1. 数据分区
    partitioned_data = data.copy()
    partitioned_data['dt'] = partition_date
    
    # 2. 数据去重
    partitioned_data = partitioned_data.drop_duplicates(
        subset=['order_id'], keep='last'
    )
    
    # 3. 写入ClickHouse
    clickhouse_client.insert_dataframe(
        f"INSERT INTO {target_table}", 
        partitioned_data
    )
    
    # 4. 更新元数据
    update_metadata(target_table, partition_date, len(partitioned_data))
```

## 📈 实时数据处理

### 1. 流式数据架构
```yaml
# Kafka配置
kafka_config:
  bootstrap_servers: "kafka1:9092,kafka2:9092,kafka3:9092"
  topics:
    - name: "order_events"
      partitions: 12
      replication_factor: 3
    - name: "sales_events"
      partitions: 12
      replication_factor: 3
    - name: "inventory_events"
      partitions: 6
      replication_factor: 3

# Flink配置
flink_config:
  parallelism: 12
  checkpoint_interval: 60000
  state_backend: "rocksdb"
  
# ClickHouse配置
clickhouse_config:
  cluster: "business_analysis_cluster"
  database: "real_time_dw"
  buffer_size: 1000000
  flush_interval: 10000
```

### 2. 实时指标计算
```sql
-- 实时销售指标表
CREATE TABLE rt_sales_metrics (
    employee_id String,
    stat_time DateTime,
    sales_amount_1h AggregateFunction(sum, Decimal64(2)),
    sales_count_1h AggregateFunction(count, UInt64),
    sales_amount_1d AggregateFunction(sum, Decimal64(2)),
    sales_count_1d AggregateFunction(count, UInt64),
    update_time DateTime DEFAULT now()
) ENGINE = AggregatingMergeTree()
PARTITION BY toYYYYMMDD(stat_time)
ORDER BY (employee_id, stat_time)
TTL stat_time + INTERVAL 7 DAY;

-- 实时指标物化视图
CREATE MATERIALIZED VIEW rt_sales_metrics_mv TO rt_sales_metrics AS
SELECT
    employee_id,
    toStartOfHour(event_time) as stat_time,
    sumState(sales_amount) as sales_amount_1h,
    countState() as sales_count_1h,
    sumState(sales_amount) as sales_amount_1d,
    countState() as sales_count_1d
FROM kafka_sales_events
GROUP BY employee_id, stat_time;
```

## 🎯 数据建模最佳实践

### 1. 星型模型设计

#### 销售主题星型模型
```
                    ┌─────────────────┐
                    │   dim_date      │
                    │  (时间维度)     │
                    └─────────────────┘
                              │
    ┌─────────────────┐      │      ┌─────────────────┐
    │  dim_employee   │      │      │  dim_customer   │
    │   (员工维度)    │      │      │   (客户维度)    │
    └─────────────────┘      │      └─────────────────┘
              │              │              │
              └──────────────┼──────────────┘
                             │
                    ┌─────────────────┐
                    │ fact_sales      │
                    │  (销售事实表)   │
                    └─────────────────┘
                             │
              ┌──────────────┼──────────────┐
              │              │              │
    ┌─────────────────┐      │      ┌─────────────────┐
    │  dim_product    │      │      │  dim_region     │
    │   (商品维度)    │      │      │   (地区维度)    │
    └─────────────────┘      │      └─────────────────┘
                             │
                    ┌─────────────────┐
                    │  dim_channel    │
                    │   (渠道维度)    │
                    └─────────────────┘
```

### 2. 数据质量管理

#### 数据质量检查规则
```python
# 数据质量检查框架
class DataQualityChecker:
    def __init__(self):
        self.rules = []

    def add_rule(self, rule):
        self.rules.append(rule)

    def check_completeness(self, df, required_columns):
        """完整性检查"""
        results = []
        for col in required_columns:
            null_count = df[col].isnull().sum()
            null_rate = null_count / len(df)
            results.append({
                'column': col,
                'null_count': null_count,
                'null_rate': null_rate,
                'status': 'PASS' if null_rate < 0.05 else 'FAIL'
            })
        return results

    def check_accuracy(self, df, column, valid_range):
        """准确性检查"""
        min_val, max_val = valid_range
        invalid_count = len(df[(df[column] < min_val) | (df[column] > max_val)])
        invalid_rate = invalid_count / len(df)

        return {
            'column': column,
            'invalid_count': invalid_count,
            'invalid_rate': invalid_rate,
            'status': 'PASS' if invalid_rate < 0.01 else 'FAIL'
        }

    def check_consistency(self, df, rule_func):
        """一致性检查"""
        violations = df[~df.apply(rule_func, axis=1)]
        violation_rate = len(violations) / len(df)

        return {
            'violation_count': len(violations),
            'violation_rate': violation_rate,
            'status': 'PASS' if violation_rate < 0.01 else 'FAIL'
        }

# 使用示例
checker = DataQualityChecker()

# 检查订单数据质量
order_quality = checker.check_completeness(
    order_df,
    ['order_id', 'customer_id', 'order_amount']
)

amount_quality = checker.check_accuracy(
    order_df,
    'order_amount',
    (0, 1000000)
)
```

### 3. 数据血缘管理

#### 血缘关系定义
```yaml
# 数据血缘配置
data_lineage:
  tables:
    - name: "ads_employee_performance"
      type: "ADS"
      dependencies:
        - table: "dws_employee_sales_1d"
          type: "DWS"
          columns:
            - source: "sales_amount"
              target: "sales_amount"
            - source: "order_count"
              target: "order_count"
        - table: "dim_employee"
          type: "DIM"
          columns:
            - source: "employee_name"
              target: "employee_name"
            - source: "department_name"
              target: "department_name"

    - name: "dws_employee_sales_1d"
      type: "DWS"
      dependencies:
        - table: "dwd_sales_detail_fact"
          type: "DWD"
          transformation: "GROUP BY employee_id, stat_date"

    - name: "dwd_sales_detail_fact"
      type: "DWD"
      dependencies:
        - table: "ods_erp_orders"
          type: "ODS"
          transformation: "JOIN with dim_product, dim_customer"
```

## 🚀 性能优化策略

### 1. 分区策略

#### 时间分区
```sql
-- 按日期分区的大表
CREATE TABLE fact_sales_detail (
    sale_id String,
    order_id String,
    customer_id String,
    employee_id String,
    product_id String,
    sale_date Date,
    sale_amount Decimal64(2),
    quantity UInt32,
    create_time DateTime
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(sale_date)  -- 按月分区
ORDER BY (customer_id, employee_id, sale_date)
TTL sale_date + INTERVAL 3 YEAR;  -- 3年后自动删除

-- 按业务维度分区
CREATE TABLE fact_inventory_change (
    change_id String,
    product_id String,
    warehouse_id String,
    change_type Enum8('IN'=1, 'OUT'=2, 'ADJUST'=3),
    change_quantity Int32,
    change_date Date,
    create_time DateTime
) ENGINE = MergeTree()
PARTITION BY (toYYYYMM(change_date), change_type)  -- 复合分区
ORDER BY (product_id, warehouse_id, change_date);
```

### 2. 索引优化

#### 主键索引设计
```sql
-- 高效的主键索引设计
CREATE TABLE dws_customer_behavior (
    customer_id String,
    behavior_date Date,
    page_views UInt32,
    session_duration UInt32,
    purchase_amount Decimal64(2),
    create_time DateTime
) ENGINE = MergeTree()
ORDER BY (customer_id, behavior_date)  -- 按查询模式设计主键
SETTINGS index_granularity = 8192;

-- 跳数索引
ALTER TABLE dws_customer_behavior
ADD INDEX idx_purchase_amount purchase_amount TYPE minmax GRANULARITY 4;

-- 布隆过滤器索引
ALTER TABLE dws_customer_behavior
ADD INDEX idx_customer_id customer_id TYPE bloom_filter GRANULARITY 1;
```

### 3. 物化视图优化

#### 预聚合视图
```sql
-- 员工销售汇总物化视图
CREATE MATERIALIZED VIEW mv_employee_sales_summary
ENGINE = SummingMergeTree()
ORDER BY (employee_id, toYYYYMM(sale_date))
AS SELECT
    employee_id,
    toYYYYMM(sale_date) as sale_month,
    sum(sale_amount) as total_sales,
    count() as order_count,
    uniq(customer_id) as customer_count
FROM fact_sales_detail
GROUP BY employee_id, sale_month;

-- 实时指标物化视图
CREATE MATERIALIZED VIEW mv_realtime_metrics
ENGINE = AggregatingMergeTree()
ORDER BY (metric_type, toStartOfMinute(event_time))
AS SELECT
    'sales' as metric_type,
    toStartOfMinute(event_time) as time_window,
    sumState(amount) as total_amount,
    countState() as event_count,
    uniqState(customer_id) as unique_customers
FROM kafka_events
WHERE event_type = 'sale'
GROUP BY metric_type, time_window;
```

## 📊 OLAP查询优化

### 1. 多维分析查询

#### 钻取查询示例
```sql
-- 销售数据钻取：年 -> 季度 -> 月 -> 日
-- 年度汇总
SELECT
    toYear(sale_date) as year,
    sum(sale_amount) as total_sales,
    count() as order_count,
    uniq(customer_id) as customer_count
FROM fact_sales_detail
WHERE sale_date >= '2024-01-01'
GROUP BY year
ORDER BY year;

-- 钻取到季度
SELECT
    toYear(sale_date) as year,
    toQuarter(sale_date) as quarter,
    sum(sale_amount) as total_sales,
    count() as order_count
FROM fact_sales_detail
WHERE toYear(sale_date) = 2024
GROUP BY year, quarter
ORDER BY year, quarter;

-- 钻取到月份
SELECT
    toYear(sale_date) as year,
    toMonth(sale_date) as month,
    sum(sale_amount) as total_sales,
    count() as order_count
FROM fact_sales_detail
WHERE toYear(sale_date) = 2024
  AND toQuarter(sale_date) = 1
GROUP BY year, month
ORDER BY year, month;
```

#### 切片切块查询
```sql
-- 按地区切片
SELECT
    r.region_name,
    sum(f.sale_amount) as total_sales,
    avg(f.sale_amount) as avg_sales
FROM fact_sales_detail f
JOIN dim_region r ON f.region_id = r.region_id
WHERE f.sale_date BETWEEN '2024-01-01' AND '2024-12-31'
GROUP BY r.region_name
ORDER BY total_sales DESC;

-- 按商品类别切块
SELECT
    p.category_name,
    toMonth(f.sale_date) as month,
    sum(f.sale_amount) as monthly_sales
FROM fact_sales_detail f
JOIN dim_product p ON f.product_id = p.product_id
WHERE f.sale_date >= '2024-01-01'
  AND p.category_name IN ('饮料', '食品', '日用品')
GROUP BY p.category_name, month
ORDER BY category_name, month;
```

### 2. 复杂分析查询

#### 同比环比分析
```sql
-- 销售同比环比分析
WITH monthly_sales AS (
    SELECT
        toYYYYMM(sale_date) as month_key,
        toYear(sale_date) as year,
        toMonth(sale_date) as month,
        sum(sale_amount) as monthly_amount
    FROM fact_sales_detail
    WHERE sale_date >= '2023-01-01'
    GROUP BY month_key, year, month
)
SELECT
    month_key,
    year,
    month,
    monthly_amount,
    -- 环比增长率
    (monthly_amount - lag(monthly_amount, 1) OVER (ORDER BY month_key)) /
    lag(monthly_amount, 1) OVER (ORDER BY month_key) * 100 as mom_growth_rate,
    -- 同比增长率
    (monthly_amount - lag(monthly_amount, 12) OVER (ORDER BY month_key)) /
    lag(monthly_amount, 12) OVER (ORDER BY month_key) * 100 as yoy_growth_rate
FROM monthly_sales
ORDER BY month_key;
```

#### RFM客户分析
```sql
-- RFM客户价值分析
WITH customer_rfm AS (
    SELECT
        customer_id,
        -- Recency: 最近购买距今天数
        dateDiff('day', max(sale_date), today()) as recency,
        -- Frequency: 购买频次
        count() as frequency,
        -- Monetary: 购买金额
        sum(sale_amount) as monetary
    FROM fact_sales_detail
    WHERE sale_date >= today() - INTERVAL 1 YEAR
    GROUP BY customer_id
),
rfm_scores AS (
    SELECT
        customer_id,
        recency,
        frequency,
        monetary,
        -- RFM评分 (1-5分)
        CASE
            WHEN recency <= 30 THEN 5
            WHEN recency <= 60 THEN 4
            WHEN recency <= 90 THEN 3
            WHEN recency <= 180 THEN 2
            ELSE 1
        END as r_score,

        CASE
            WHEN frequency >= 20 THEN 5
            WHEN frequency >= 10 THEN 4
            WHEN frequency >= 5 THEN 3
            WHEN frequency >= 2 THEN 2
            ELSE 1
        END as f_score,

        CASE
            WHEN monetary >= 50000 THEN 5
            WHEN monetary >= 20000 THEN 4
            WHEN monetary >= 10000 THEN 3
            WHEN monetary >= 5000 THEN 2
            ELSE 1
        END as m_score
    FROM customer_rfm
)
SELECT
    customer_id,
    r_score,
    f_score,
    m_score,
    concat(toString(r_score), toString(f_score), toString(m_score)) as rfm_code,
    CASE
        WHEN r_score >= 4 AND f_score >= 4 AND m_score >= 4 THEN '重要价值客户'
        WHEN r_score >= 4 AND f_score >= 3 AND m_score >= 3 THEN '重要发展客户'
        WHEN r_score >= 3 AND f_score >= 4 AND m_score >= 4 THEN '重要保持客户'
        WHEN r_score >= 3 AND f_score >= 3 AND m_score >= 3 THEN '重要挽留客户'
        WHEN r_score <= 2 AND f_score >= 3 AND m_score >= 3 THEN '一般价值客户'
        ELSE '一般客户'
    END as customer_segment
FROM rfm_scores
ORDER BY r_score DESC, f_score DESC, m_score DESC;
```

## 🔧 数据治理框架

### 1. 元数据管理

#### 元数据模型
```sql
-- 表元数据
CREATE TABLE metadata_tables (
    table_id String,
    database_name String,
    table_name String,
    table_type Enum8('ODS'=1, 'DWD'=2, 'DWS'=3, 'DIM'=4, 'ADS'=5),
    description String,
    owner String,
    create_time DateTime,
    update_time DateTime,
    row_count UInt64,
    data_size UInt64,
    partition_key String,
    sort_key String,
    ttl_expression String
) ENGINE = MergeTree()
ORDER BY (database_name, table_name);

-- 字段元数据
CREATE TABLE metadata_columns (
    column_id String,
    table_id String,
    column_name String,
    data_type String,
    is_nullable UInt8,
    default_value String,
    description String,
    business_rules String,
    data_quality_rules String,
    create_time DateTime,
    update_time DateTime
) ENGINE = MergeTree()
ORDER BY (table_id, column_name);

-- 数据血缘关系
CREATE TABLE metadata_lineage (
    lineage_id String,
    source_table_id String,
    target_table_id String,
    source_column String,
    target_column String,
    transformation_logic String,
    dependency_type Enum8('DIRECT'=1, 'INDIRECT'=2),
    create_time DateTime,
    update_time DateTime
) ENGINE = MergeTree()
ORDER BY (source_table_id, target_table_id);
```

### 2. 数据安全管理

#### 权限控制策略
```sql
-- 创建角色
CREATE ROLE data_analyst;
CREATE ROLE data_engineer;
CREATE ROLE business_user;

-- 分配权限
-- 数据分析师：可以查询所有DWS和ADS层数据
GRANT SELECT ON business_dw.dws_* TO data_analyst;
GRANT SELECT ON business_dw.ads_* TO data_analyst;

-- 数据工程师：可以操作所有层级数据
GRANT ALL ON business_dw.* TO data_engineer;

-- 业务用户：只能查询ADS层数据
GRANT SELECT ON business_dw.ads_* TO business_user;

-- 行级安全控制
CREATE ROW POLICY employee_data_policy ON business_dw.ads_employee_performance
FOR SELECT USING employee_id IN (
    SELECT employee_id
    FROM dim_employee
    WHERE manager_id = currentUser()
) TO business_user;
```

### 3. 数据监控告警

#### 监控指标定义
```python
# 数据监控配置
monitoring_config = {
    "data_freshness": {
        "tables": ["dws_employee_sales_1d", "dws_customer_consume_1d"],
        "max_delay_hours": 2,
        "alert_channels": ["email", "slack"]
    },

    "data_quality": {
        "completeness_threshold": 0.95,
        "accuracy_threshold": 0.99,
        "consistency_threshold": 0.98,
        "alert_channels": ["email", "dingding"]
    },

    "system_performance": {
        "query_timeout_seconds": 300,
        "cpu_usage_threshold": 80,
        "memory_usage_threshold": 85,
        "disk_usage_threshold": 90,
        "alert_channels": ["email", "sms"]
    }
}

# 监控任务实现
class DataMonitor:
    def check_data_freshness(self, table_name, max_delay_hours):
        """检查数据新鲜度"""
        sql = f"""
        SELECT
            max(dt) as latest_partition,
            dateDiff('hour', toDateTime(max(dt)), now()) as delay_hours
        FROM {table_name}
        """
        result = self.execute_query(sql)

        if result['delay_hours'] > max_delay_hours:
            self.send_alert(
                f"数据延迟告警: {table_name} 数据延迟 {result['delay_hours']} 小时",
                "data_freshness"
            )

    def check_data_volume(self, table_name, expected_range):
        """检查数据量异常"""
        sql = f"""
        SELECT count() as row_count
        FROM {table_name}
        WHERE dt = yesterday()
        """
        result = self.execute_query(sql)

        min_count, max_count = expected_range
        if not (min_count <= result['row_count'] <= max_count):
            self.send_alert(
                f"数据量异常: {table_name} 昨日数据量 {result['row_count']}",
                "data_volume"
            )
```

---

**文档版本**: v1.0
**最后更新**: 2024年8月14日
**维护团队**: 数据团队

> 📊 **重要说明**: 本文档提供了完整的数据仓库设计方案，包括分层架构、建模规范、ETL流程、性能优化和数据治理等方面。在实际实施时，请根据具体业务需求和技术环境进行调整。
```
